{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 16 13:36:25 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    23W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    78W / 250W |  23107MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    41W / 250W |  28023MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    34W / 250W |   1527MiB / 32768MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "CPU 갯수 =  40\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]     =  'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]  =  '0'\n",
    "print(\"CPU 갯수 = \", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "# !pip freeze > /workspace/sunggu/0.Challenge/requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Fix Seed]\n",
    "I want you to act as a AI developer in pytorch and python code for me. \n",
    "Fix the randomness of numpy, pytorch, cuda, and random function for reproducibility.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 시드(seed) 설정\n",
    "seed = 42\n",
    "\n",
    "# Python의 random 모듈 시드 설정\n",
    "random.seed(seed)\n",
    "\n",
    "# Numpy 시드 설정\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Torch 시드 설정\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Dataset]\n",
    "I want you to act as a AI developer in pytorch and python code for me. \n",
    "Please help with creating the dataset class that process image processing and augmentation based on binary classification deep learning framework.\n",
    "\n",
    "===INFO===\n",
    "data_dir = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/dataset'\n",
    "csv_file = 'rsna_data.csv'\n",
    "target_class = 'cancer'\n",
    "\n",
    "Code for creating the RSNA breast cancer dataset class called \"RSNA_Dataset\". \n",
    "This code is a custom dataset class that inherits \"Dataset\" from PyTorch. \n",
    "The dataset can be initialized in either \"train\" or \"valid\" mode and reads the file path and label information from the corresponding CSV file.\n",
    "\n",
    "Each entry in the dataset is defined as follows:\n",
    "- Read the DICOM file using the image path.\n",
    "- Apply the Modality Lookup Table (LUT) and Value of Interest (VOI) LUT for the pixel array in the DICOM file.\n",
    "- Returns the read image and the corresponding label.\n",
    "\n",
    "In addition to the dataset class, we define an compose transform function that performs data preprocessing and augmentation through the \"get_transforms\" function using Albumentation Library. \n",
    "\n",
    "Please conduct step by step using the following procedure.\n",
    "\t1. In the training mode, perform image resizing (224x224), minmax normalization, change_to_uint8, Contrast Limited Adaptive Histogram Equation (CLAHE), change_to_float32, horizontal flip, brightness and contrast adjustment, Shift-Scale-Rotate conversion, image inversion, minmax normalization, and tensor conversion. \n",
    "    2. In validation mode, perform image resizing (224x224), minmax normalization, change_to_uint8, fixed CLAHE, change_to_float32, minmax normalization, and tensor conversion. \n",
    "\t3. Finally, create \"train_dataset\" and \"valid_dataset\" and create a DataLoader that loads them into \"train_loader\" and \"valid_loader\". \"train_loader\" and \"valid_loader\" can be used for training and validation.\n",
    "\n",
    "Here is a example template:\n",
    "<\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "\n",
    "    class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # Load the data from the specified directory\n",
    "        # ...\n",
    "        \n",
    "        # Preprocess the data\n",
    "        # ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return the data and labels for the specified index\n",
    "        # ...\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of data samples\n",
    "        # ...\n",
    "\n",
    "    # 1. Create Dataset\n",
    "        # ...\n",
    "    # 2. Create DataLoader\n",
    "        # ...\n",
    ">\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import skimage\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from pydicom.pixel_data_handlers.util import apply_modality_lut, apply_voi_lut\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def list_sort_nicely(l):\n",
    "    def convert(text): return int(text) if text.isdigit() else text\n",
    "    def alphanum_key(key): return [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "def fixed_clahe(image, **kwargs):\n",
    "    clahe_mat = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe_mat.apply(image)\n",
    "\n",
    "def change_to_uint8(image, **kwargs):\n",
    "    return skimage.util.img_as_ubyte(image)\n",
    "\n",
    "def change_to_float32(image, **kwargs):\n",
    "    return skimage.util.img_as_float32(image)\n",
    "\n",
    "def min_max_normalization(image, **kwargs):\n",
    "    if len(np.unique(image)) != 1:\n",
    "        image = image.astype('float32')\n",
    "        image -= image.min()\n",
    "        image /= image.max() \n",
    "    return image\n",
    "\n",
    "def get_transforms(mode=\"train\"):\n",
    "    # medical augmentation\n",
    "    if mode == \"train\":\n",
    "        return A.Compose([\n",
    "            # Preprocessing\n",
    "            A.Resize(224, 224), # 7*2**5 = 224\n",
    "            A.Lambda(image=min_max_normalization, always_apply=True),\n",
    "            A.Lambda(image=change_to_uint8, always_apply=True),\n",
    "            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), always_apply=True),\n",
    "            A.Lambda(image=change_to_float32, always_apply=True),\n",
    "\n",
    "            # Augmentation\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # A.RandomBrightnessContrast(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "            A.InvertImg(p=0.5),\n",
    "\n",
    "            # Normalize\n",
    "            A.Lambda(image=min_max_normalization, always_apply=True),\n",
    "            A.Normalize(max_pixel_value=1.0, mean=0.5, std=0.5),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            # Preprocessing\n",
    "            A.Resize(224, 224),\n",
    "            A.Lambda(image=min_max_normalization, always_apply=True),\n",
    "            A.Lambda(image=change_to_uint8, always_apply=True),\n",
    "            A.Lambda(image=fixed_clahe, always_apply=True),\n",
    "            A.Lambda(image=change_to_float32, always_apply=True),\n",
    "            \n",
    "            # Normalize\n",
    "            A.Lambda(image=min_max_normalization, always_apply=True),\n",
    "            A.Normalize(max_pixel_value=1.0, mean=0.5, std=0.5),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.root       = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/dataset/rsna_data.csv'\n",
    "        temp_df         = pd.read_csv(self.root)\n",
    "        self.data_df    = temp_df[temp_df['mode'] == mode]\n",
    "        self.transforms = get_transforms(mode=mode)\n",
    "        print(f\"len of data: {len(self.data_df)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_df['path'].iloc[idx]\n",
    "        dcm_data = pydicom.dcmread(img_path)\n",
    "        temp_img = apply_modality_lut(dcm_data.pixel_array, dcm_data)   \n",
    "        image    = apply_voi_lut(temp_img, dcm_data)                             \n",
    "\n",
    "        label    = self.data_df['cancer'].iloc[idx]\n",
    "        label    = torch.tensor(label).float().unsqueeze(0)\n",
    "\n",
    "        # add channel axis\n",
    "        image    = np.expand_dims(image, axis=-1)\n",
    "        image    = self.transforms(image=image)['image']\n",
    "        \n",
    "        return image, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data: 1852\n",
      "len of data: 232\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Create Dataset\n",
    "train_dataset = RSNA_Dataset(mode=\"train\")\n",
    "valid_dataset = RSNA_Dataset(mode=\"valid\")\n",
    "\n",
    "# 2. Create DataLoader\n",
    "train_loader  = DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=40)\n",
    "valid_loader  = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "class Resnet50(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet50(pretrained=pretrained)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(2048, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = ViTModel(ViTConfig())\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunggu/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Learnable Params: 23503809\n"
     ]
    }
   ],
   "source": [
    "model = Resnet50(pretrained=True) # Resnet50\n",
    "# model = ViT(pretrained=True) # ViT\n",
    "    \n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of Learnable Params:', n_parameters)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Loss function]\n",
    "I want you to act as a deep learning expert and code for me. \n",
    "I already have a “RSNA_Dataset” of Mammography Breast Cancer. \n",
    "Please design a popular loss def function in binary classification task and define the loss as \"criterion\".\n",
    "The target and predict(logit) are given in this function and they should be same shape.\n",
    "The predict is the state before the non-linear activation layer.\n",
    "Give me a simple example of how to use it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 인기 있는 손실 함수인 이진 교차 엔트로피 손실(Binary Cross Entropy Loss)을 사용합니다.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 예시 사용법\n",
    "# target = torch.tensor([0, 1, 0, 1])\n",
    "# logit = torch.tensor([-1.2, 2.5, -0.8, 1.7])\n",
    "# loss = criterion(logit, target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Optimizer]\n",
    "I want you to act as a deep learning expert and code for me. \n",
    "I already have a “RSNA_Dataset” of Mammography Breast Cancer. \n",
    "Please design some popular or SOTA optimizers in binary classification network.\n",
    "Learning rate is 1e-4.\n",
    "weight_dacay is 0.\n",
    "Other optimizer's params are set default.\n",
    "Please discuss optimizer hyperparams' key features and use cases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "# optimizer = optim.AdamW(params=model.parameters(), lr=1e-4, weight_decay=0) # 230616 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, amsgrad=False)  \n",
    "# optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-2, amsgrad=False) # 230615 model\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False) # 230616 model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define learning rate(LR) scheduler]\n",
    "I want you to act as a deep learning expert and code for me. \n",
    "Please design some popular or SOTA LR schedulers in binary classification network.\n",
    "LR scheduler's params are set default.\n",
    "Please discuss LR scheduler hyperparams' key features and use cases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# scheduler = lr_scheduler.StepLR(optimizer)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Check the resume point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Resume training]\n",
    "I want you to act as a deep learning expert and code for me. \n",
    "Please code for loading the model weight from the checkpoint if it is exist.\n",
    "\n",
    "==INFO===\n",
    "start_epoch     = 0\n",
    "total_epoch     = 1000\n",
    "checkpoint_dir  = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/checkpoints/230616_ResNet50'\n",
    "save_dir        = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/predictions/230616_ResNet50'\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
    "\n",
    "Please conduct step by step using the following procedure.\n",
    "    1. make checkpoints and prediction folders if not exist (using exist_ok=True)\n",
    "    2. load model, optimizer, scheduler, start_epoch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch     = 0\n",
    "total_epoch     = 1000\n",
    "checkpoint_dir  = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/checkpoints/230616_ResNet50'\n",
    "save_dir        = '/workspace/sunggu/0.Challenge/Med_tutorial_ChatGPT/predictions/230616_ResNet50'\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pth')\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 파일이 존재하는 경우 모델 가중치 로드\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "print(\"모델 가중치를 체크포인트에서 성공적으로 불러왔습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer Error fix...!\n",
    "# for state in optimizer.state.values():\n",
    "#     for k, v in state.items():\n",
    "#         if torch.is_tensor(v):\n",
    "#             state[k] = v.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Using the DataParallel for multi-gpu training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Multi-Gpu Training]\n",
    "I want you to act as a deep learning expert and code for me. \n",
    "Please code for using multi-gpu training (DataParallel) of the model.\n",
    "First, check the cuda if it is available.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "# CUDA 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# 모델 정의\n",
    "# 이미 \"model\"이 정의되어 있다고 가정합니다.\n",
    "\n",
    "# 모델을 CUDA 장치로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "# 멀티 GPU 학습을 위해 모델을 DataParallel로 감싸기\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Metrics]\n",
    "I want you to act as a deep-learning expert and code for me. \n",
    "Please def function code for metrics in binary classification for cancer detection.\n",
    "Here is what I want metrics: AUC, accuracy, f1, sensitivity, specificity...\n",
    "Give me a simple example of how to use it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, recall_score, confusion_matrix, precision_score\n",
    "\n",
    "def calculate_metrics(predictions, targets):\n",
    "    # AUC 계산\n",
    "    auc = roc_auc_score(targets, predictions)\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(targets, np.round(predictions))\n",
    "\n",
    "    # F1 점수 계산\n",
    "    f1 = f1_score(targets, np.round(predictions))\n",
    "\n",
    "    # 민감도 (재현율) 계산\n",
    "    sensitivity = recall_score(targets, np.round(predictions))\n",
    "\n",
    "    # 특이도 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(targets, np.round(predictions)).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return auc, accuracy, f1, sensitivity, specificity\n",
    "\n",
    "# # 예시 사용법\n",
    "# predictions = [0.8, 0.3, 0.6, 0.9]\n",
    "# targets = [1, 0, 0, 1]\n",
    "# auc, accuracy, f1, sensitivity, specificity = calculate_metrics(predictions, targets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Training & Validation Loop function]\n",
    "I want you to act as a deep-learning expert and code for me. \n",
    "Please create the loop def function code for training and validation. \n",
    "In this code, you will use the AverageMeter class to calculate the average of the metrics, and the train_loop_fn function and the valid_loop_fn function to perform the training and validation process. \n",
    "In addition, the train_loop_fn function and the valid_loop_fn function will utilize a loss function (criterion) to calculate the loss, which will be used to calculate the metrics using 'calculate_metrics' function (accuracy, F1, AUC, sensitivity, and specificity).\n",
    "\n",
    "Please conduct step by step using the following procedure.\n",
    "\t1. understand the AverageMeter class and how it calculates the average of the metrics.\n",
    "\t2. understand the structure and role of the train_loop_fn and valid_loop_fn functions.\n",
    "\t3. see how to utilize the loss function (criterion) to calculate loss.\n",
    "\t4. understand how to calculate the metrics (accuracy, F1, AUC, sensitivity, specificity) using calculate_metrics function used in the train_loop_fn and valid_loop_fn functions.\n",
    "\t5. train_loader, model, criterion, optimizer, device, epoch are given in train_loop_fn.\n",
    "\t6. valid_loader, model, criterion, device, epoch are given in valid_loop_fn.\n",
    "    7. analyze the methods (update, average) of AverageMeter that are called by the train_loop_fn and valid_loop_fn functions.\n",
    "\t8. Implement a training and validation loop based on the given code, and check the resulting metrics.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = defaultdict(lambda: {'sum': 0, 'count': 0})\n",
    "\n",
    "    def update(self, key, value, n):\n",
    "        self.data[key]['sum'] += value * n\n",
    "        self.data[key]['count'] += n\n",
    "    \n",
    "    def average(self):\n",
    "        return {k: v['sum'] / v['count'] for k, v in self.data.items()}\n",
    "\n",
    "def train_loop_fn(train_loader, model, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    metric_logger = AverageMeter()\n",
    "    # epoch_iterator = tqdm(train_loader, desc=f\"Training (Epoch {epoch})\")\n",
    "    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True, total=len(train_loader))\n",
    "\n",
    "    for step, batch_data in enumerate(epoch_iterator):\n",
    "        image, target = batch_data\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        logit = model(image)\n",
    "        loss = criterion(logit, target)\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_logger.update(key='train_loss', value=loss_value, n=image.shape[0])\n",
    "        metric_logger.update(key='lr', value=optimizer.param_groups[0][\"lr\"], n=1)    \n",
    "        epoch_iterator.set_description(\"Training: Epochs %d (%d / %d Steps), (train_loss=%2.5f)\" % (epoch, step, len(train_loader), loss_value))\n",
    "        # epoch_iterator.set_postfix(loss=loss_value)\n",
    "\n",
    "    # return {k: round(v, 7) for k, v in metric_logger.average().items()}\n",
    "    return metric_logger.average()\n",
    "    \n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_loop_fn(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    metric_logger = AverageMeter()\n",
    "    # epoch_iterator = tqdm(valid_loader, desc=\"Validating\")\n",
    "    epoch_iterator = tqdm(valid_loader, desc=\"Validating (X / X Steps) (loss=X.X)\", dynamic_ncols=True, total=len(valid_loader))\n",
    "\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for batch_data in epoch_iterator:\n",
    "        image, target = batch_data\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        logit = model(image)\n",
    "        loss = criterion(logit, target)\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "\n",
    "        metric_logger.update(key='valid_loss', value=loss_value, n=image.shape[0])\n",
    "        # epoch_iterator.set_postfix(loss=loss_value)\n",
    "        epoch_iterator.set_description(\"Validating: Epochs %d (%d / %d Steps), (valid_loss=%2.5f)\" % (epoch, step, len(valid_loader), loss_value))\n",
    "\n",
    "        preds.append(logit.sigmoid().squeeze().detach().cpu().numpy())\n",
    "        gts.append(target.squeeze().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    gts = np.concatenate(gts)\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc, accuracy, f1, sensitivity, specificity = calculate_metrics(preds, gts)\n",
    "\n",
    "    metric_logger.update(key='valid_loss', value=loss.item(), n=image.size(0))\n",
    "    metric_logger.update(key='valid_auc', value=auc, n=image.size(0))\n",
    "    metric_logger.update(key='valid_accuracy', value=accuracy, n=image.size(0))\n",
    "    metric_logger.update(key='valid_f1', value=f1, n=image.size(0))\n",
    "    metric_logger.update(key='valid_sensitivity', value=sensitivity, n=image.size(0))\n",
    "    metric_logger.update(key='valid_specificity', value=specificity, n=image.size(0))\n",
    "\n",
    "    return metric_logger.average()\n",
    "    # return {k: round(v, 7) for k, v in metric_logger.average().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Implementation Training & Validation]\n",
    "I want you to act as a deep-learning expert and code for me. \n",
    "You are given a code that trains a model using a training loop and performs validation using a validation loop. \n",
    "The code also includes functionality for saving checkpoints, updating the learning rate scheduler, and logging the training and validation statistics. \n",
    "\n",
    "Please conduct step by step using the following procedure:\n",
    "\tStep 1: Import the necessary libraries and modules for the code, including warnings, time, and datetime.\n",
    "\tStep 2: Set up a warning filter to ignore any warnings that occur during execution.\n",
    "\tStep 3: Print a message indicating the start of the training process.\n",
    "\tStep 4: Start a loop that iterates over the specified number of epochs, ranging from the start_epoch to the total_epoch.\n",
    "\tStep 5: Within each epoch, call the train_loop_fn function to perform the training process. Pass the train_loader, model, criterion, optimizer, device, and current epoch as arguments. Store the returned training statistics in a variable.\n",
    "\tStep 6: Print the averaged training statistics.\n",
    "\tStep 7: Call the valid_loop_fn function to perform the validation process. Pass the valid_loader, model, criterion, device, and current epoch as arguments. Also, provide the save_dir where the checkpoints will be saved. Store the returned validation statistics in a variable.\n",
    "\tStep 8: Print the averaged validation statistics.\n",
    "\tStep 9: Adjust the learning rate scheduler using the valid_loss from the validation statistics.\n",
    "\tStep 10: Save a checkpoint of the current model, including the epoch, model_state_dict, optimizer_state_dict, and scheduler_state_dict. The checkpoint should be saved in a designated checkpoint_path with a filename that includes the epoch number.\n",
    "\tStep 11: Log the training and validation statistics, including the epoch, learning rate, and both train and valid statistics. The statistics should be stored in a log file located in the checkpoint_path.\n",
    "\tStep 12: Repeat steps 4-11 until all epochs have been completed.\n",
    "\tStep 13: Calculate the total training time by subtracting the start_time from the current time. Format the total time as a human-readable string.\n",
    "\tStep 14: Print the total training time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "print(\"학습 시작\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    train_stats = train_loop_fn(train_loader, model, criterion, optimizer, device, epoch)\n",
    "    print(\"==> 평균 학습 통계: \" + str(train_stats))\n",
    "    \n",
    "    valid_stats = valid_loop_fn(valid_loader, model, criterion, device, epoch, save_dir)\n",
    "    print(\"==> 평균 검증 통계: \" + str(valid_stats))\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    scheduler.step(valid_stats['valid_loss'])\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    checkpoint_path = f\"{save_dir}/epoch_{epoch}_checkpoint.pth\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.module.state_dict() if hasattr(model, 'module') else model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    # 로그 기록\n",
    "    log_stats = {**{f'train_{k}': v for k, v in train_stats.items()}, \n",
    "                 **{f'valid_{k}': v for k, v in valid_stats.items()}, \n",
    "                 'epoch': epoch,\n",
    "                 'lr': optimizer.param_groups[0]['lr']}\n",
    "      \n",
    "    with open(f\"{save_dir}/log.txt\", \"a\") as f:\n",
    "        f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "# 학습 완료\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('학습 시간: {}'.format(total_time_str))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
