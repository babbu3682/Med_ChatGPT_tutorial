{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/babbu3682/Med_ChatGPT_tutorial/blob/main/Notebook/colab/Hands_On_Train_Base.ipynb)\n",
    "\n",
    "- ##### '파일' -> '드라이브에 사본 저장' 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬에서 경고 메시지를 끄기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install pydicom\n",
    "!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg # GDCM 에러 해결\n",
    "!pip install albumentations==0.5.2\n",
    "!pip install pytorch-gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 한글깨짐 현상 해결 코드\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "\n",
    "import matplotlib.pyplot as plt # matplotlob import 하기\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic' # 나눔바른고딕 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab과 google drive 연동 (마운트)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # /content에 Med_ChatGPT_tutorial 폴더가 생성됨.\n",
    "!git clone https://github.com/babbu3682/Med_ChatGPT_tutorial.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리:\n",
    "# 위의 두 코드를 실행했다면,\n",
    "# 데이터 경로는 /content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset\n",
    "# 코드 경로는 /content/Med_ChatGPT_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 클릭 -> 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi # GPU 정보 확인하기\n",
    "import os\n",
    "print(\"CPU 갯수 = \", os.cpu_count()) # CPU 갯수 확인하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Seed Fixed]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \n",
    "\n",
    "===TASK===\n",
    "재현성을 위해 numpy, pytorch, cuda, and random 라이브러리의 무작위성을 고정하는 코드를 작성해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Numpy\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# CUDA\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Random\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Create Dataset]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \n",
    "dicom image 처리 및 증강을 포함하는 binary classification 작업용 딥러닝 프레임워크를 기반으로 데이터셋 클래스를 생성해 주세요.\n",
    "PyTorch의 \"Dataset\"을 상속받는 맞춤형 데이터셋 클래스 \"RSNA_Dataset\"을 생성하는 코드입니다.\n",
    "이미지의 경로가 포함된 csv 파일('rsna_data.csv')을 읽어들여서 데이터셋을 생성해 주세요.\n",
    "이미 'rsna_data.csv'의 'mode'열로 'train', 'valid'로 데이터를 구분해 두었습니다.\n",
    "'albumentations' 라이브러리를 사용하여 데이터 전처리 및 증강을 수행하는 compose transform 함수를 정의합니다. \n",
    "'mode'에 따라 증강을 다르게 적용합니다.\n",
    "'train' 모드 증강으로는, Resize(224x224), min_max_normalization, 텐서 변환을 수행합니다. \n",
    "'valid' 모드 증강으로는, Resize(224x224), min_max_normalization, 텐서 변환을 수행합니다. \n",
    "\n",
    "===INFO===\n",
    "csv_file = '/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv'\n",
    "target_class = 'cancer'\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. csv 파일을 읽습니다.\n",
    "    2. 초기단계에서 해당 'mode'에 따라 데이터 프레임을 필터링 합니다.\n",
    "    3. 데이터 프레임의 'path'열을 사용하여 파일 경로, 'cancer'열을 사용하여 라벨 정보를 읽습니다.\n",
    "    4. DICOM 파일의 픽셀 배열에 Modality Lookup Table (LUT)를 적용합니다.\n",
    "    5. 해당 'mode'에 따른 augmentation을 적용합니다.\n",
    "    6. 읽은 이미지와 해당 라벨을 반환합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성(1/2)\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Compose, Resize, Normalize\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode, target_class):\n",
    "        # csv 파일 읽기\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 라벨 컬럼명\n",
    "        self.target_class = target_class\n",
    "        # 'mode'에 따른 Augmentation 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                Normalize(),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                Normalize(),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로 읽기\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일 읽기\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT 적용\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 Augmentation\n",
    "        img = self.transform(image=img)['image']\n",
    "\n",
    "        # 라벨 정보 읽기\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc(self.target_class)]\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \n",
    "위 코드에 불완전한 부분이 있습니다. 코드를 다시 작성하여 완성도를 높여주세요. \n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 필수 사항입니다:\n",
    "    1. 굳이 target_class에 변수를 부여하지 않아도 됩니다. target_class는 항상 'cancer' 입니다.\n",
    "    2. A.Normalize() 대신 min_max_normalization 함수를 생성하고, 이를 이용하여 normalize 하세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성(2/2)\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Compose, Resize\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # csv 파일 읽기\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 'mode'에 따른 Augmentation 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로 읽기\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일 읽기\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT 적용\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # Min-Max 정규화\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "        # 이미지 Augmentation\n",
    "        img = self.transform(image=img)['image']\n",
    "\n",
    "        # 라벨 정보 읽기\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \n",
    "위 코드에 불완전한 부분이 있습니다. 코드를 다시 작성하여 완성도를 높여주세요. \n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 수정사항입니다:\n",
    "  1. 정규화는 augmentation 다음에 위치하도록 수정해주세요.\n",
    "  2. label도 텐서로 변형해야 합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Compose, Resize\n",
    "import albumentations as A\n",
    "import torch\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # csv 파일 읽기\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 'mode'에 따른 Augmentation 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로 읽기\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일 읽기\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT 적용\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 Augmentation\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화 (Augmentation 이후에 적용)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 라벨 정보 읽기\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 라벨을 텐서로 변환\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue writing please\n",
    "# or\n",
    "# \"train_dataset\" 및 \"valid_dataset\"을 생성하고 이를 \"train_loader\" 및 \"valid_loader\"에 로드하는 DataLoader를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 훈련 및 검증 데이터셋 로드\n",
    "train_dataset = RSNA_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"train\")\n",
    "valid_dataset = RSNA_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"valid\")\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "b = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Build a Neural Network]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "'Pytorch'를 사용하여 인기있는 비전 신경망 'ResNet50'을 구축해 주세요.\n",
    "입력 채널과 출력 채널은 '1'입니다.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 비전 신경망 라이브러리를 임포트합니다.\n",
    "    2. 모델 'ResNet50' class를 선언합니다.\n",
    "    3. 학습 가능한 파라미터 수를 계산합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        # torchvision에서 제공하는 ResNet50 모델 로드\n",
    "        self.model = resnet50(pretrained=False)\n",
    "        # 입력 채널을 1로 변경\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # 출력 채널을 1로 변경\n",
    "        self.model.fc = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# 모델 선언\n",
    "model = ResNet50()\n",
    "\n",
    "# 훈련 가능한 매개변수의 수 계산\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"훈련 가능한 매개변수의 수: {trainable_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Multi-GPU Training]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "멀티 GPU를 사용하여 모델을 학습하고자 합니다.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 먼저 GPU를 사용할 수 있는지 확인합니다.\n",
    "    2. multi-gpu를 사용할 수 있는지 확인합니다.\n",
    "    3. multi-gpu를 사용할 수 있다면, multi-gpu를 사용하여 모델을 래핑합니다.\n",
    "    4. multi-gpu를 사용할 수 없다면, 단일 GPU를 사용합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GPU가 사용 가능한지 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU를 사용할 수 있습니다.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU를 사용할 수 없습니다. CPU를 사용합니다.\")\n",
    "\n",
    "# 멀티-GPU 사용 가능한지 확인\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"멀티-GPU를 사용할 수 있습니다. GPU 개수: {torch.cuda.device_count()}\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Loss function]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "이진 분류 작업에서 많이 사용되는 손실 함수를 정의하고 손실을 \"loss\"으로 정의해 주세요.\n",
    "이 함수에는 'target'와 'logit'이 주어지며, 같은 shape이어야 합니다.\n",
    "사용 방법에 대한 간단한 예를 제공해주세요.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 손실 함수를 정의합니다.\n",
    "    2. 손실 함수를 사용하는 간단한 예를 제공합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss_fn(logit, target):\n",
    "    loss = F.binary_cross_entropy_with_logits(logit, target)\n",
    "    return loss\n",
    "\n",
    "# 간단한 예시\n",
    "logit = torch.randn(10, requires_grad=True)  # 모델의 출력을 가정합니다.\n",
    "target = torch.empty(10).random_(2)  # 이진 타겟 레이블을 가정합니다.\n",
    "loss = loss_fn(logit, target)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Optimizer]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "인기 있는 'optimizer' 여러 개를 소개하고, 설계하세요.\n",
    "학습률은 '1e-4'이고 'weight_dacay'는 '0'입니다.\n",
    "'optimizer' 하이퍼파라미터의 주요 기능 및 사용 사례에 대해 설명해 주세요.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 여러 'optimizer'를 정의합니다.\n",
    "    2. 각 'optimizer' 하이퍼파라미터의 주요 기능 및 사용 사례에 대해 설명합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# # SGD 최적화기\n",
    "# optimizer_SGD = optim.SGD(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "\n",
    "# # Momentum 최적화기\n",
    "# optimizer_Momentum = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, weight_decay=0)\n",
    "\n",
    "# # RMSprop 최적화기\n",
    "# optimizer_RMSprop = optim.RMSprop(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "\n",
    "# Adam 최적화기\n",
    "# optimizer_Adam = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define learning rate(LR) scheduler]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "인기 있는 'scheduler' 여러 개를 소개하고, 설계하세요.\n",
    "'scheduler'의 하이퍼파라미터는 default로 설정하고 하이퍼파라미터의 주요 기능 및 사용 사례에 대해 설명해 주세요.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 여러 'scheduler'를 정의합니다.\n",
    "    2. 각 'scheduler' 하이퍼파라미터의 주요 기능 및 사용 사례에 대해 설명합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# # StepLR 스케줄러\n",
    "# scheduler_stepLR = lr_scheduler.StepLR(optimizer_Adam, step_size=30, gamma=0.1)\n",
    "\n",
    "# # MultiStepLR 스케줄러\n",
    "# scheduler_multiStepLR = lr_scheduler.MultiStepLR(optimizer_Adam, milestones=[30, 80], gamma=0.1)\n",
    "\n",
    "# # ExponentialLR 스케줄러\n",
    "# scheduler_expLR = lr_scheduler.ExponentialLR(optimizer_Adam, gamma=0.1)\n",
    "\n",
    "# ReduceLROnPlateau 스케줄러\n",
    "# scheduler_ReduceLROnPlateau = lr_scheduler.ReduceLROnPlateau(optimizer_Adam, 'min')\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check the resume point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Resume training]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "체크포인트가 있는 경우 체크포인트에서 모델 웨이트를 로드하도록 코딩하세요.\n",
    "\n",
    "==INFO===\n",
    "start_epoch     = 0\n",
    "total_epoch     = 200\n",
    "checkpoint_dir  = '/content/Med_ChatGPT_tutorial/checkpoints/230701_ResNet50_Base'\n",
    "save_dir        = '/content/Med_ChatGPT_tutorial/predictions/230701_ResNet50_Base'\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 'checkpoint_dir' 및 'save_dir'에 폴더가 존재하지 않는 경우 폴더를 만듭니다.\n",
    "    2. 'checkpoint_dir'에 체크포인트가 있는지 확인합니다.\n",
    "    3. 체크포인트가 있는 경우, model weight, optimizer, scheduler, start_epoch를 로드합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch     = 0\n",
    "total_epoch     = 200\n",
    "checkpoint_dir  = '/content/Med_ChatGPT_tutorial/checkpoints/230701_ResNet50_Base'\n",
    "save_dir        = '/content/Med_ChatGPT_tutorial/predictions/230701_ResNet50_Base'\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 체크포인트 및 저장 디렉토리 생성\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 체크포인트 존재 여부 확인\n",
    "ckpt_path = os.path.join(checkpoint_dir, 'last_checkpoint.pth')\n",
    "if os.path.exists(ckpt_path):\n",
    "    # 체크포인트가 존재하는 경우, 가중치, 옵티마이저, 스케줄러, 시작 에포크 로드\n",
    "    print(\"체크포인트 로드 중...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(\"체크포인트 로드 완료. 훈련을 {} 에포크부터 재개합니다.\".format(start_epoch))\n",
    "else:\n",
    "    # 체크포인트가 없는 경우, 초기 에포크로 설정\n",
    "    print(\"체크포인트를 찾을 수 없습니다. 훈련을 처음부터 시작합니다.\")\n",
    "    start_epoch = 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Metrics]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "암 검출을 위한 binary classification task 평가 메트릭에 대한 함수 코드를 정의해 주세요.\n",
    "사용 방법에 대한 간단한 예제를 알려주세요.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 평가 메트릭에 대한 함수 코드를 정의합니다.\n",
    "    2. 평가 메트릭에 대한 간단한 예제를 제공합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(target, prediction):\n",
    "    # 정밀도, 재현율, F1 점수를 계산합니다.\n",
    "    precision = precision_score(target, prediction)\n",
    "    recall = recall_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류 평가 지표를 더 추가해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def calculate_metrics(target, prediction, prob):\n",
    "    # 정확도, 정밀도, 재현율, F1 점수, AUC-ROC를 계산합니다.\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    precision = precision_score(target, prediction)\n",
    "    recall = recall_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    auc_roc = roc_auc_score(target, prob)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc_roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 타깃과 예측값, 예측 확률\n",
    "target = [1, 0, 1, 1, 0, 1]\n",
    "prediction = [0, 0, 1, 1, 0, 1]\n",
    "prob = [0.1, 0.2, 0.8, 0.9, 0.3, 0.7]\n",
    "\n",
    "# 평가 지표 계산\n",
    "accuracy, precision, recall, f1, auc_roc = calculate_metrics(target, prediction, prob)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-score: \", f1)\n",
    "print(\"AUC-ROC: \", auc_roc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Training & Validation Loop function]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "AverageMeter 클래스를 선언하고 이를 통해 loss 및 평가 지표 값을 기록하세요.\n",
    "train_loop_fn 함수와 valid_loop_fn 함수를 선언하세요.\n",
    "start_epoch부터 total_epoch까지 반복하는 루프를 시작합니다.\n",
    "valid_loop가 끝날 때마다 model, optimizer, scheduler들의 weight와, epoch, lr을 text 형태로 저장하세요.\n",
    "학습에 걸린 시간을 재주세요.\n",
    "\n",
    "==INFO===\n",
    "'calculate_metrics' 함수가 이미 정의되어 있습니다, 이를 이용하세요.\n",
    "'loss_fn' 함수가 이미 정의되어 있습니다, 이를 이용하세요.\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. AverageMeter class 정의하세요.\n",
    "    2. train_loop_fn를 정의하세요.\n",
    "    3. valid_loop_fn를 정의하세요.\n",
    "    4. start_epoch부터 total_epoch까지 반복하는 루프를 시작합니다.\n",
    "    5. valid_loop가 끝날 때마다 model, optimizer, scheduler들의 weight와, epoch, lr을 text 형태로 저장하세요.\n",
    "    6. 학습에 걸린 시간을 계산합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (1/5)\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "\n",
    "    print(f'Train Epoch: {epoch}, Loss: {loss_meter.avg:.6f}')\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "\n",
    "    print(f'Valid Epoch: {epoch}, Loss: {loss_meter.avg:.6f}')\n",
    "\n",
    "# 훈련 및 검증 루프\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, total_epoch):\n",
    "    train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "    valid_loop_fn(epoch, valid_loader, model, device)\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, f'{checkpoint_dir}/checkpoint_{epoch}.pth')\n",
    "\n",
    "print(f'Total training time: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요.\n",
    "위 코드에 불완전한 부분이 있습니다. 코드를 다시 작성하여 완성도를 높여주세요.\n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 수정사항입니다:\n",
    "  0. valid_loop_fn에서 평가 지표를 계산하고 출력해주세요.\n",
    "  1. train_loop_fn와 valid_loop_fn에서 loss 및 평가 지표 결과를 반환해주세요.\n",
    "  2. 반환된 loss_meter.avg를 print 해주세요.\n",
    "  3. 반환된 loss_meter.avg를 log로 기록하고 'log.txt'로 저장합니다.\n",
    "  4. 스케줄러 업데이트를 루프에 추가해주세요. (ReduceLROnPlateau)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (2/5)\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "\n",
    "    print(f'Train Epoch: {epoch}, Loss: {loss_meter.avg:.6f}')\n",
    "    return loss_meter.avg\n",
    "\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    metrics_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        metrics = calculate_metrics(outputs.detach().cpu(), targets.detach().cpu())\n",
    "        \n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "        metrics_meter.update(metrics, images.size(0))\n",
    "        \n",
    "    print(f'Valid Epoch: {epoch}, Loss: {loss_meter.avg:.6f}, Metrics: {metrics_meter.avg:.6f}')\n",
    "    return loss_meter.avg, metrics_meter.avg\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "        \n",
    "        log_file.write(f'Epoch {epoch}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(valid_loss)\n",
    "        \n",
    "        # 체크포인트 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "        }, f'{checkpoint_dir}/checkpoint_{epoch}.pth')\n",
    "\n",
    "print(f'Total training time: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요.\n",
    "위 코드에 불완전한 부분이 있습니다. 코드를 다시 작성하여 완성도를 높여주세요.\n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 수정사항입니다:\n",
    "  1. learning_rate도 log_file에 기록해주세요.\n",
    "  2. 체크포인트에 learning_rate도 저장해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (3/5)\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "\n",
    "    print(f'Train Epoch: {epoch}, Loss: {loss_meter.avg:.6f}')\n",
    "    return loss_meter.avg\n",
    "\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    metrics_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        metrics = calculate_metrics(outputs.detach().cpu(), targets.detach().cpu())\n",
    "        \n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "        metrics_meter.update(metrics, images.size(0))\n",
    "        \n",
    "    print(f'Valid Epoch: {epoch}, Loss: {loss_meter.avg:.6f}, Metrics: {metrics_meter.avg:.6f}')\n",
    "    return loss_meter.avg, metrics_meter.avg\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "        \n",
    "        # 학습률 기록\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        log_file.write(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "        print(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(valid_loss)\n",
    "        \n",
    "        # 체크포인트 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'current_lr': current_lr  # 학습률 저장\n",
    "        }, f'{checkpoint_dir}/checkpoint_{epoch}.pth')\n",
    "\n",
    "print(f'Total training time: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (4/5)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)  # 입력 텐서의 데이터 타입을 FloatTensor로 변환\n",
    "        target = target.float().to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), image.size(0))\n",
    "        pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "    return loss_meter.avg\n",
    "\n",
    "\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    metrics_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.float().to(device)\n",
    "        targets = targets.float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        metrics = calculate_metrics(outputs.detach().cpu(), targets.detach().cpu())\n",
    "\n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "        metrics_meter.update(metrics, images.size(0))\n",
    "\n",
    "    print(f'Valid Epoch: {epoch}, Loss: {loss_meter.avg:.6f}, Metrics: {metrics_meter.avg:.6f}')\n",
    "    return loss_meter.avg, metrics_meter.avg\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "\n",
    "        # 학습률 기록\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        log_file.write(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "        print(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'current_lr': current_lr  # 학습률 저장\n",
    "        }, f'{checkpoint_dir}/checkpoint_{epoch}.pth')\n",
    "\n",
    "print(f'Total training time: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG FIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (5/5)\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)\n",
    "        target = target.float().unsqueeze(1).to(device)  # 목표 텐서의 차원을 추가합니다.\n",
    "\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), image.size(0))\n",
    "        pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "    return loss_meter.avg\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    metrics_meter = AverageMeter()\n",
    "    for i, (images, targets) in enumerate(loader):\n",
    "        images = images.float().to(device)\n",
    "        targets = targets.float().unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        metrics = calculate_metrics(outputs.detach().cpu(), targets.detach().cpu())\n",
    "\n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "        metrics_meter.update(metrics, images.size(0))\n",
    "\n",
    "    print(f'Valid Epoch: {epoch}, Loss: {loss_meter.avg:.6f}, Metrics: {metrics_meter.avg:.6f}')\n",
    "    return loss_meter.avg, metrics_meter.avg\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "\n",
    "        # 학습률 기록\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        log_file.write(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "        print(f'Epoch {epoch}, LR: {current_lr}, Train Loss: {train_loss}, Valid Loss: {valid_loss}, Metrics: {valid_metrics}\\n')\n",
    "\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'current_lr': current_lr  # 학습률 저장\n",
    "        }, f'{checkpoint_dir}/checkpoint_{epoch}.pth')\n",
    "\n",
    "print(f'Total training time: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요.\n",
    "\n",
    "===INFO===\n",
    "def calculate_metrics(target, prediction, prob):\n",
    "    # 정확도, 정밀도, 재현율, F1 점수, AUC-ROC를 계산합니다.\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    precision = precision_score(target, prediction)\n",
    "    recall = recall_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    auc_roc = roc_auc_score(target, prob)\n",
    "    return accuracy, precision, recall, f1, auc_roc\n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 수정사항입니다:\n",
    "  1. 'calculate_metrics' 함수는 accuracy, precision, recall, f1, auc_roc를 반환합니다. valid_loop_fn와 전체 루프를 수정해주세요.\n",
    "  2. 평가는 valid_loop가 끝나고 스택된 outputs과 targets를 이용하여 한번에 계산합니다.\n",
    "  3. 전체 루프에서 log_file에 'string'형식보다 '사전'형식으로 기록해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)\n",
    "        target = target.float().unsqueeze(1).to(device)  # 목표 텐서의 차원을 추가합니다.\n",
    "\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), image.size(0))\n",
    "        pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "    return loss_meter.avg\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    outputs, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, total=len(loader))\n",
    "        for i, (image, target) in enumerate(pbar):\n",
    "            image = image.float().to(device)\n",
    "            target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss_meter.update(loss.item(), image.size(0))\n",
    "            pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "            outputs.append(output.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "\n",
    "    return loss_meter.avg, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        log_file.write(json.dumps({\"epoch\": epoch, \"train_loss\": train_loss, \"valid_loss\": valid_loss, **valid_metrics}) + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Log analysis]\n",
    "파이토치 및 파이썬 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요.\n",
    "로그 파일에서 데이터를 읽고 그래프로 시각화하는 기능을 구현하기 위한 코딩을 도와주세요.\n",
    "\n",
    "===INFO===\n",
    "log_file = '/content/log.txt'\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "\t1단계: 필요한 라이브러리 및 모듈을 가져옵니다\n",
    "\t2단계: log_file 읽습니다.\n",
    "\t3단계: loss에 대해서는 오름차순으로 5개의 값을 출력합니다.\n",
    "\t4단계: 평가 지표에 대해서는 내림차순으로 5개의 값을 출력합니다.\n",
    "\t5단계: 각 변수에 대한 그래프를 그립니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 필요한 라이브러리와 모듈을 가져옵니다.\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2단계: 로그 파일을 읽습니다.\n",
    "log_data = []\n",
    "# with open('/content/log.txt', 'r') as log_file:\n",
    "with open('/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/230701_ResNet50_Base/log.txt', 'r') as log_file:\n",
    "    for line in log_file:\n",
    "        log_data.append(json.loads(line))\n",
    "log_df = pd.DataFrame(log_data)\n",
    "\n",
    "# 3단계: 손실에 대해 오름차순으로 5개의 값을 출력합니다.\n",
    "print(log_df.sort_values('valid_loss')[:5])\n",
    "\n",
    "# 4단계: 평가 지표에 대해 내림차순으로 5개의 값을 출력합니다.\n",
    "print(log_df.sort_values('accuracy', ascending=False)[:5])\n",
    "print(log_df.sort_values('precision', ascending=False)[:5])\n",
    "print(log_df.sort_values('recall', ascending=False)[:5])\n",
    "print(log_df.sort_values('f1', ascending=False)[:5])\n",
    "print(log_df.sort_values('auc_roc', ascending=False)[:5])\n",
    "\n",
    "# 5단계: 각 변수에 대해 그래프를 그립니다.\n",
    "metrics = ['train_loss', 'valid_loss', 'accuracy', 'precision', 'recall', 'f1', 'auc_roc']\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(log_df[metric], label=metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Epoch vs {metric}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_Test_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # csv 파일 읽기\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        self.transform = Compose([\n",
    "            Resize(224, 224),\n",
    "            ToTensorV2()\n",
    "          ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 파일 경로 읽기\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일 읽기\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT 적용\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 Augmentation\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화 (Augmentation 이후에 적용)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 라벨 정보 읽기\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 라벨을 텐서로 변환\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# TEST 데이터셋 생성\n",
    "test_dataset = RSNA_Test_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"test\")\n",
    "\n",
    "# DataLoader 설정\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric  =  accuracy\n",
    "# Argsort =  [ 4  5  7 12 68]\n",
    "# Value   =  [0.60344828 0.60344828 0.59051724 0.5862069  0.58189655]\n",
    "\n",
    "# filename = '/content/Med_ChatGPT_tutorial/checkpoints/230701_ResNet50_Base'\n",
    "filename = '/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/230701_ResNet50_Base/epoch_4_checkpoint.pth'\n",
    "\n",
    "print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "checkpoint  = torch.load(filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using GPU testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Define Training & Validation Loop function]\n",
    "===INSTRUCT===\n",
    "딥러닝 전문가가 되어 저를 위해 코딩해 주셨으면 합니다.\n",
    "'valid_loop_fn' 함수를 참고하여 'test_loop_fn' 함수를 정의하고, 실행하세요.\n",
    "모델의 마지막 컨볼루션 레이어의 Grad-CAM을 그려주세요.\n",
    "Test에 걸린 시간을 재주세요.\n",
    "\n",
    "==INFO===\n",
    "'valid_loop_fn'는 다음과 같습니다:\n",
    "<\n",
    "def valid_loop_fn(epoch, loader, model, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    outputs, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, total=len(loader))\n",
    "        for i, (image, target) in enumerate(pbar):\n",
    "            image = image.float().to(device)\n",
    "            target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss_meter.update(loss.item(), image.size(0))\n",
    "            pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "            outputs.append(output.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "\n",
    "    return loss_meter.avg, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    ">\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. test_loop_fn를 정의하세요.\n",
    "    2. test_loop_fn을 수행하세요.\n",
    "    3. TEST에 걸린 시간을 계산합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 가져옵니다.\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# AverageMeter 클래스를 정의합니다.\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# 1단계: test_loop_fn를 정의합니다.\n",
    "def test_loop_fn(loader, model, device):\n",
    "    model.eval()\n",
    "    outputs, targets = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, total=len(loader))\n",
    "        for i, (image, target) in enumerate(pbar):\n",
    "            image = image.float().to(device)\n",
    "            target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            outputs.append(output.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "    print(f\"Test Metrics: {metrics}\")\n",
    "\n",
    "    # 시간을 측정하고 출력합니다.\n",
    "    end_time = time.time()\n",
    "    print(f\"Total test time: {end_time - start_time} seconds\")\n",
    "\n",
    "# 2단계: TEST_LOOP_FN를 실행합니다.\n",
    "test_loop_fn(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Code Completion]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요.\n",
    "위 코드에 불완전한 부분이 있습니다. 코드를 다시 작성하여 완성도를 높여주세요.\n",
    "\n",
    "===TASK===\n",
    "다음은 몇 가지 필수 사항입니다:\n",
    "    0. pytorch-gradcam를 설치하세요.\n",
    "    1. 'test_loop_fn'에 추가적으로 Grad-CAM을 사용하여 모델의 마지막 컨볼루션 레이어에 대한 시각화 코드를 작성해주세요.\n",
    "    2. grad-cam과 원본 image를 겹쳐서 보여주세요.\n",
    "    3. figure의 title에 모델의 결과와 label 값을 나타내주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/vickyliin/gradcam_plus_plus-pytorch/blob/master/example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 설치합니다.\n",
    "!pip install pytorch-gradcam\n",
    "\n",
    "# 필요한 라이브러리를 가져옵니다.\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAMpp, GradCAM\n",
    "\n",
    "# test_loop_fn를 수정하고 Grad-CAM 시각화를 추가합니다.\n",
    "def test_loop_fn(loader, model, device):\n",
    "    model.eval()\n",
    "    outputs, targets = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 마지막 컨볼루션 레이어의 Grad-CAM을 설정합니다.\n",
    "    grad_cam = GradCAM(model, model.model.layer4)\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)\n",
    "        target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        # Grad-CAM 마스크를 생성합니다.\n",
    "        mask, _ = grad_cam(image)\n",
    "        heatmap, result = visualize_cam(mask, image)\n",
    "\n",
    "        outputs.append(output.detach().cpu())\n",
    "        targets.append(target.detach().cpu())\n",
    "\n",
    "        # 원본 이미지와 Grad-CAM 결과를 함께 출력합니다.\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image.cpu().squeeze().numpy())\n",
    "        plt.title(f\"Label: {target.item()}\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(result.cpu().squeeze().numpy().transpose(1, 2, 0))\n",
    "        plt.title(f\"Model Result: {output.sigmoid().item()}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "    print(f\"Test Metrics: {metrics}\")\n",
    "\n",
    "    # 시간을 측정하고 출력합니다.\n",
    "    end_time = time.time()\n",
    "    print(f\"Total test time: {end_time - start_time} seconds\")\n",
    "\n",
    "# test_loop_fn를 실행합니다.\n",
    "test_loop_fn(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch-gradcam 라이브러리를 사용하여 정확한 Grad-CAM 예제를 제공하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.autograd import Variable\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# ResNet50 모델을 불러오고, eval 모드로 설정합니다.\n",
    "model = resnet50(pretrained=True)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "\n",
    "# 이미지를 불러오고, 전처리를 합니다.\n",
    "img_path = \"/path/to/your/image.jpg\"\n",
    "img = cv2.imread(img_path, 1)\n",
    "img = np.float32(img) / 255\n",
    "input_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "preprocessed_img = input_transforms(img).unsqueeze(0)\n",
    "input_tensor = Variable(preprocessed_img, requires_grad=True).cuda()\n",
    "\n",
    "# Grad-CAM을 준비합니다. 여기서는 ResNet의 마지막 conv 레이어를 대상으로 합니다.\n",
    "target_layer = model.layer4[-1]\n",
    "cam = GradCAM(model=model, target_layer=target_layer, use_cuda=True)\n",
    "\n",
    "# Grad-CAM을 계산합니다.\n",
    "target_category = None  # None으로 설정하면 가장 높은 점수의 카테고리가 대상이 됩니다.\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n",
    "\n",
    "# 원본 이미지에 Grad-CAM을 입힙니다.\n",
    "visualization = show_cam_on_image(img, grayscale_cam)\n",
    "\n",
    "# 결과를 시각화합니다.\n",
    "plt.imshow(visualization)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test_auc'       : 0.5961938745168004,\n",
    "'test_accuracy'   : 0.5948275862068966,\n",
    "'test_f1'         : 0.626984126984127,\n",
    "'test_sensitivity': 0.6694915254237288,\n",
    "'test_specificity': 0.5175438596491229\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
