{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/babbu3682/Med_ChatGPT_tutorial/blob/main/Notebook/colab/Hands_On_Train_Aug_L2.ipynb)\n",
    "\n",
    "- ##### '파일' -> '드라이브에 사본 저장' 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install pydicom\n",
    "!pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg # GDCM 에러 해결\n",
    "!pip install albumentations==0.5.2\n",
    "!pip install pytorch-gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 한글깨짐 현상 해결 코드\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "\n",
    "import matplotlib.pyplot as plt # matplotlob import 하기\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic' # 나눔바른고딕 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab과 google drive 연동 (마운트)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /content에 Med_ChatGPT_tutorial 폴더가 생성됨.\n",
    "!git clone https://github.com/babbu3682/Med_ChatGPT_tutorial.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리:\n",
    "# 위의 두 코드를 실행했다면,\n",
    "# 데이터 경로는 /content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset\n",
    "# 코드 경로는 /content/Med_ChatGPT_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 클릭 -> 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi # GPU 정보 확인하기\n",
    "import os\n",
    "print(\"CPU 갯수 = \", os.cpu_count()) # CPU 갯수 확인하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Numpy\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# CUDA\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Random\n",
    "random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n[Create Dataset]\\n===INSTRUCT===\\n파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \\ntemplate에 따라 코드를 작성하시기 바랍니다.\\n\\n'train' 모드 증강으로는, Resize(224x224), min_max_normalization, 텐서 변환을 수행합니다. \\n'valid' 모드 증강으로는, Resize(224x224), min_max_normalization, 텐서 변환을 수행합니다. \\n\\n===INFO===\\ntemplate = {\\n\\n===TASK===\\n다음 절차에 따라 단계별로 진행하시기 바랍니다:\\n    1. csv 파일을 읽습니다.\\n    2. 초기단계에서 해당 'mode'에 따라 데이터 프레임을 필터링 합니다.\\n    3. 데이터 프레임의 'path'열을 사용하여 파일 경로, 'cancer'열을 사용하여 라벨 정보를 읽습니다.\\n    4. DICOM 파일의 픽셀 배열에 Modality Lookup Table (LUT)를 적용합니다.\\n    5. 해당 'mode'에 따른 augmentation을 적용합니다.\\n    6. 읽은 이미지와 해당 라벨을 반환합니다.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[Create Dataset]\n",
    "===INSTRUCT===\n",
    "파이토치 및 파이썬에서 AI 개발자 역할을 맡아 저를 위해 코딩해 주세요. \n",
    "TEMPLATE를 참고하여 RSNA_Dataset class를 재작성하시기 바랍니다.\n",
    "Augmentation을 강화하려고 합니다. \n",
    "기존 'train' 모드 증강에 추가로, CLAHE, horizontal flip, brightness and contrast adjustment, invert, Shift-Scale-Rotate등 강력한 augmentation 조합을 수행합니다.\n",
    "\n",
    "===INFO===\n",
    "TEMPLATE = \n",
    "[\n",
    "    class RSNA_Dataset(Dataset):\n",
    "        def __init__(self, csv_file, mode):\n",
    "            # csv 파일 읽기\n",
    "            self.dataframe = pd.read_csv(csv_file)\n",
    "            # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "            self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "            # 'mode'에 따른 Augmentation 설정\n",
    "            if mode == 'train':\n",
    "                self.transform = Compose([\n",
    "                    Resize(224, 224),\n",
    "                    ToTensorV2()\n",
    "                ])\n",
    "            elif mode == 'valid':\n",
    "                self.transform = Compose([\n",
    "                    Resize(224, 224),\n",
    "                    ToTensorV2()\n",
    "                ])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dataframe)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            if torch.is_tensor(idx):\n",
    "                idx = idx.tolist()\n",
    "\n",
    "            # 이미지 파일 경로 읽기\n",
    "            img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "            # DICOM 파일 읽기\n",
    "            dicom = pydicom.dcmread(img_path)\n",
    "            # LUT 적용\n",
    "            img = dicom.pixel_array\n",
    "            img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "            # 이미지 Augmentation\n",
    "            img = self.transform(image=img)['image']\n",
    "            # Min-Max 정규화 (Augmentation 이후에 적용)\n",
    "            img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "            # 라벨 정보 읽기\n",
    "            label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "            # 라벨을 텐서로 변환\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "            return img, label\n",
    "]\n",
    "\n",
    "===TASK===\n",
    "다음 절차에 따라 단계별로 진행하시기 바랍니다:\n",
    "    1. 제공된 'TEMPLATE'를 참고하여 'RSNA_Dataset' class를 재작성합니다.\n",
    "    2. 기존 augmentation에 추가로 CLAHE, horizontal flip, brightness and contrast adjustment, invert, Shift-Scale-Rotate등 강력한 augmentation 조합을 수행합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (1/2)\n",
    "from albumentations import (\n",
    "    Compose, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,\n",
    "    ShiftScaleRotate, IAAAdditiveGaussianNoise, Transpose, CLAHE, InvertImg\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # CSV 파일을 읽습니다.\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임을 필터링합니다.\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 'mode'에 따른 증강 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                CLAHE(),  # CLAHE 적용\n",
    "                HorizontalFlip(),  # 수평 플립 적용\n",
    "                RandomBrightnessContrast(),  # 밝기 및 대비 조정\n",
    "                InvertImg(),  # 이미지 반전\n",
    "                ShiftScaleRotate(),  # 시프트, 스케일, 회전 적용\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로를 읽습니다.\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일을 읽습니다.\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT를 적용합니다.\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 증강을 적용합니다.\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화를 적용합니다. (증강 후에 적용합니다)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 레이블 정보를 읽습니다.\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 레이블을 텐서로 변환합니다.\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미완성 (2/2)\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import (\n",
    "    Compose, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,\n",
    "    ShiftScaleRotate, IAAAdditiveGaussianNoise, Transpose, CLAHE, InvertImg\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # CSV 파일을 읽습니다.\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임을 필터링합니다.\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 'mode'에 따른 증강 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                CLAHE(),  # CLAHE 적용\n",
    "                HorizontalFlip(),  # 수평 플립 적용\n",
    "                RandomBrightnessContrast(),  # 밝기 및 대비 조정\n",
    "                InvertImg(),  # 이미지 반전\n",
    "                ShiftScaleRotate(),  # 시프트, 스케일, 회전 적용\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로를 읽습니다.\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일을 읽습니다.\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT를 적용합니다.\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 증강을 적용합니다.\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화를 적용합니다. (증강 후에 적용합니다)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 레이블 정보를 읽습니다.\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 레이블을 텐서로 변환합니다.\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import (\n",
    "    Compose, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,\n",
    "    ShiftScaleRotate, IAAAdditiveGaussianNoise, Transpose, CLAHE, InvertImg\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "\n",
    "class RSNA_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # CSV 파일을 읽습니다.\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임을 필터링합니다.\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        # 'mode'에 따른 증강 설정\n",
    "        if mode == 'train':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                CLAHE(p=0.5),  # CLAHE 적용\n",
    "                HorizontalFlip(p=0.5),  # 수평 플립 적용\n",
    "                RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, brightness_by_max=True, always_apply=False, p=0.5),  # 밝기 및 대비 조정\n",
    "                InvertImg(p=0.5),  # 이미지 반전\n",
    "                ShiftScaleRotate(p=0.5),  # 시프트, 스케일, 회전 적용\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif mode == 'valid':\n",
    "            self.transform = Compose([\n",
    "                Resize(224, 224),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # 이미지 파일 경로를 읽습니다.\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일을 읽습니다.\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT를 적용합니다.\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지를 uint8로 변환합니다.\n",
    "        img = img.astype(np.uint8)\n",
    "        # 이미지 증강을 적용합니다.\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화를 적용합니다. (증강 후에 적용합니다)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 레이블 정보를 읽습니다.\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 레이블을 텐서로 변환합니다.\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 훈련 및 검증 데이터셋 로드\n",
    "train_dataset = RSNA_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"train\")\n",
    "valid_dataset = RSNA_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"valid\")\n",
    "\n",
    "# DataLoader 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, num_workers=2, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, num_workers=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_loader))\n",
    "b = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(20):\n",
    "  plt.imshow(a[0][i].squeeze(0), 'gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomBrightnessContrast과 ShiftScaleRotate의 파라미터를 알려주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://albumentations.ai/docs/api_reference/augmentations/transforms/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        # torchvision에서 제공하는 ResNet50 모델 로드\n",
    "        self.model = resnet50(pretrained=False)\n",
    "        # 입력 채널을 1로 변경\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # 출력 채널을 1로 변경\n",
    "        self.model.fc = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# 모델 선언\n",
    "model = ResNet50()\n",
    "\n",
    "# 훈련 가능한 매개변수의 수 계산\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"훈련 가능한 매개변수의 수: {trainable_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GPU가 사용 가능한지 확인\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "    print(\"GPU를 사용할 수 있습니다.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU를 사용할 수 없습니다. CPU를 사용합니다.\")\n",
    "\n",
    "# 멀티-GPU 사용 가능한지 확인\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"멀티-GPU를 사용할 수 있습니다. GPU 개수: {torch.cuda.device_count()}\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss_fn(logit, target):\n",
    "    loss = F.binary_cross_entropy_with_logits(logit, target)\n",
    "    return loss\n",
    "\n",
    "# 간단한 예시\n",
    "logit = torch.randn(10, requires_grad=True)  # 모델의 출력을 가정합니다.\n",
    "target = torch.empty(10).random_(2)  # 이진 타겟 레이블을 가정합니다.\n",
    "loss = loss_fn(logit, target)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-4, weight_decay=5e-2) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check the resume point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch     = 0\n",
    "total_epoch     = 200\n",
    "checkpoint_dir  = '/content/Med_ChatGPT_tutorial/checkpoints/230701_ResNet50_Aug_L2'\n",
    "save_dir        = '/content/Med_ChatGPT_tutorial/predictions/230701_ResNet50_Aug_L2'\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 체크포인트 및 저장 디렉토리 생성\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 체크포인트 존재 여부 확인\n",
    "ckpt_path = os.path.join(checkpoint_dir, 'last_checkpoint.pth')\n",
    "if os.path.exists(ckpt_path):\n",
    "    # 체크포인트가 존재하는 경우, 가중치, 옵티마이저, 스케줄러, 시작 에포크 로드\n",
    "    print(\"체크포인트 로드 중...\")\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    print(\"체크포인트 로드 완료. 훈련을 {} 에포크부터 재개합니다.\".format(start_epoch))\n",
    "else:\n",
    "    # 체크포인트가 없는 경우, 초기 에포크로 설정\n",
    "    print(\"체크포인트를 찾을 수 없습니다. 훈련을 처음부터 시작합니다.\")\n",
    "    start_epoch = 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "def calculate_metrics(target, prediction, prob):\n",
    "    # 정확도, 정밀도, 재현율, F1 점수, AUC-ROC를 계산합니다.\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    precision = precision_score(target, prediction)\n",
    "    recall = recall_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    auc_roc = roc_auc_score(target, prob)\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc_roc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"평균 및 합계을 계산하기 위한 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def train_loop_fn(epoch, loader, model, loss_fn, optimizer, device, scheduler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)\n",
    "        target = target.float().unsqueeze(1).to(device)  # 목표 텐서의 차원을 추가합니다.\n",
    "\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_meter.update(loss.item(), image.size(0))\n",
    "        pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "    return loss_meter.avg\n",
    "\n",
    "def valid_loop_fn(epoch, loader, model, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter()\n",
    "    outputs, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, total=len(loader))\n",
    "        for i, (image, target) in enumerate(pbar):\n",
    "            image = image.float().to(device)\n",
    "            target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss_meter.update(loss.item(), image.size(0))\n",
    "            pbar.set_postfix(loss=loss_meter.avg)\n",
    "\n",
    "            outputs.append(output.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "\n",
    "    return loss_meter.avg, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "\n",
    "with open('log.txt', 'w') as log_file:\n",
    "    for epoch in range(start_epoch, total_epoch):\n",
    "        train_loss = train_loop_fn(epoch, train_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        valid_loss, valid_metrics = valid_loop_fn(epoch, valid_loader, model, device)\n",
    "\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        log_file.write(json.dumps({\"epoch\": epoch, \"train_loss\": train_loss, \"valid_loss\": valid_loss, **valid_metrics}) + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Log 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: 필요한 라이브러리와 모듈을 가져옵니다.\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2단계: 로그 파일을 읽습니다.\n",
    "log_data = []\n",
    "# with open('/content/log.txt', 'r') as log_file:\n",
    "with open('/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/230701_ResNet50_Aug_L2/log.txt', 'r') as log_file:\n",
    "    for line in log_file:\n",
    "        log_data.append(json.loads(line))\n",
    "log_df = pd.DataFrame(log_data)\n",
    "\n",
    "# 3단계: 손실에 대해 오름차순으로 5개의 값을 출력합니다.\n",
    "print(log_df.sort_values('valid_loss')[:5])\n",
    "\n",
    "# 4단계: 평가 지표에 대해 내림차순으로 5개의 값을 출력합니다.\n",
    "print(log_df.sort_values('accuracy', ascending=False)[:5])\n",
    "print(log_df.sort_values('precision', ascending=False)[:5])\n",
    "print(log_df.sort_values('recall', ascending=False)[:5])\n",
    "print(log_df.sort_values('f1', ascending=False)[:5])\n",
    "print(log_df.sort_values('auc_roc', ascending=False)[:5])\n",
    "\n",
    "# 5단계: 각 변수에 대해 그래프를 그립니다.\n",
    "metrics = ['train_loss', 'valid_loss', 'accuracy', 'precision', 'recall', 'f1', 'auc_roc']\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(log_df[metric], label=metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'Epoch vs {metric}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNA_Test_Dataset(Dataset):\n",
    "    def __init__(self, csv_file, mode):\n",
    "        # csv 파일 읽기\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        # 초기 단계에서 'mode'에 따라 데이터 프레임 필터링\n",
    "        self.dataframe = self.dataframe[self.dataframe['mode'] == mode]\n",
    "        self.transform = Compose([\n",
    "            Resize(224, 224),\n",
    "            ToTensorV2()\n",
    "          ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 파일 경로 읽기\n",
    "        img_path = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('path')]\n",
    "        # DICOM 파일 읽기\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        # LUT 적용\n",
    "        img = dicom.pixel_array\n",
    "        img = img * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "        # 이미지 Augmentation\n",
    "        img = self.transform(image=img)['image']\n",
    "        # Min-Max 정규화 (Augmentation 이후에 적용)\n",
    "        img = (img - torch.min(img)) / (torch.max(img) - torch.min(img))\n",
    "\n",
    "        # 라벨 정보 읽기\n",
    "        label = self.dataframe.iloc[idx, self.dataframe.columns.get_loc('cancer')]\n",
    "        # 라벨을 텐서로 변환\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# TEST 데이터셋 생성\n",
    "test_dataset = RSNA_Test_Dataset(csv_file=\"/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/rsna_data.csv\", mode=\"test\")\n",
    "\n",
    "# DataLoader 설정\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'epoch_53_checkpoint.pth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric  =  accuracy\n",
    "# Argsort =  [53 62 58 19 39]\n",
    "# Value   =  [0.65086207 0.65086207 0.65086207 0.65086207 0.65086207]\n",
    "\n",
    "# filename = '/content/Med_ChatGPT_tutorial/checkpoints/230701_ResNet50_Aug_L2'\n",
    "filename = '/content/drive/MyDrive/Med_ChatGPT_tutorial_Dataset/230701_ResNet50_Aug_L2/epoch_53_checkpoint.pth'\n",
    "\n",
    "print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "checkpoint  = torch.load(filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using GPU testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[Define Test Loop function]\\nI want you to act as an AI developer in pytorch and python code for me. \\nPlease help with writing a code that performs testing on a model using a testing loop. \\nIn this code, you will use the AverageMeter class to calculate the average of the metrics, and the test_loop_fn function to perform the testing process.\\nThe code includes functionalities such as calculating metrics, generating Grad-CAM visualizations, and saving the visualizations.\\nIn addition, the test_loop_fn function will utilize a loss function (criterion) to calculate the loss, which will be used to calculate the metrics using \\'calculate_metrics\\' function (accuracy, F1, AUC, sensitivity, and specificity).\\nThe model predicts cancer within an image in a binary classification manner.\\n\\nPlease conduct step by step using the following procedure:\\n\\tStep 1: Import the necessary libraries and modules for the code, including time, math, json, tqdm, datetime, matplotlib.pyplot, and defaultdict.\\n\\tStep 2: Define the AverageMeter class, which will be used to calculate the average of metrics.\\n\\tStep 3: Define the forward_hook function, which serves as the forward hook for capturing intermediate activations.\\n\\tStep 4: Define the backward_hook function, which serves as the backward hook for capturing gradients.\\n\\tStep 5: Define the min_max_normalization function, which performs min-max normalization on the input image.\\n\\tStep 6: Define the test_loop_fn function, which performs testing using the provided model, criterion, and data. The function takes the test_loader, model, criterion, device, and save_dir as arguments.\\n\\tStep 7: Set the model to evaluation mode.\\n\\tStep 8: Initialize the metric_logger to track the metrics during testing.\\n\\tStep 9: Iterate over the batches in the test_loader using the tqdm iterator.\\n\\tStep 10: Get the input images and targets from the batch.\\n\\tStep 11: Register the forward_hook and backward_hook on the specified layer of the model (resnet50\\'s layer4[2].conv3).\\n\\tStep 12: Pass the input images through the model to obtain the logits.\\n\\tStep 13: Calculate the loss using the criterion.\\n\\tStep 14: Update the metric_logger with the loss value.\\n\\tStep 15: Perform post-processing steps, such as storing the predicted probabilities and ground truth values.\\n\\tStep 16: Calculate the Grad-CAM visualization by computing the gradients and activations.\\n\\tStep 17: Resize the Grad-CAM heatmap to the original image size.\\n\\tStep 18: Visualize the image and Grad-CAM heatmap using matplotlib.pyplot.\\n\\tStep 19: Save the visualization to a file in the specified save_dir.\\n\\tStep 20: Remove the forward_hook and backward_hook.\\n\\tStep 21: Concatenate the predicted probabilities and ground truth values to calculate metrics.\\n\\tStep 22: Calculate the metrics (AUC, accuracy, F1, sensitivity, specificity) using the calculate_metrics function.\\n\\tStep 23: Update the metric_logger with the calculated metrics.\\n\\tStep 24: Return the average of the metrics and the ground truth values.\\n\\nHere is a valid_loop example, so you can refer to it:\\n<\\n@torch.no_grad()\\ndef valid_loop_fn(valid_loader, model, criterion, device):\\n    model.eval()\\n    metric_logger = AverageMeter()\\n    # epoch_iterator = tqdm(valid_loader, desc=\"Validating\")\\n    epoch_iterator = tqdm(valid_loader, desc=\"Validating (X / X Steps) (loss=X.X)\", dynamic_ncols=True, total=len(valid_loader))\\n\\n    preds = []\\n    gts = []\\n    for batch_data in epoch_iterator:\\n        image, target = batch_data\\n        image, target = image.to(device), target.to(device)\\n\\n        logit = model(image)\\n        loss = criterion(logit, target)\\n        loss_value = loss.item()\\n\\n        if not math.isfinite(loss_value):\\n            print(\"Loss is {}, stopping training\".format(loss_value))\\n\\n        metric_logger.update(key=\\'valid_loss\\', value=loss_value, n=image.shape[0])\\n        # epoch_iterator.set_postfix(loss=loss_value)\\n        epoch_iterator.set_description(\"Validating: Epochs %d (%d / %d Steps), (valid_loss=%2.5f)\" % (epoch, step, len(valid_loader), loss_value))\\n\\n        preds.append(logit.sigmoid().squeeze().detach().cpu().numpy())\\n        gts.append(target.squeeze().detach().cpu().numpy())\\n\\n    preds = np.concatenate(preds)\\n    gts = np.concatenate(gts)\\n\\n    # Calculate metrics\\n    auc, accuracy, f1, sensitivity, specificity = calculate_metrics(preds, gts)\\n\\n    metric_logger.update(key=\\'valid_loss\\', value=loss.item(), n=image.size(0))\\n    metric_logger.update(key=\\'valid_auc\\', value=auc, n=image.size(0))\\n    metric_logger.update(key=\\'valid_accuracy\\', value=accuracy, n=image.size(0))\\n    metric_logger.update(key=\\'valid_f1\\', value=f1, n=image.size(0))\\n    metric_logger.update(key=\\'valid_sensitivity\\', value=sensitivity, n=image.size(0))\\n    metric_logger.update(key=\\'valid_specificity\\', value=specificity, n=image.size(0))\\n\\n    return metric_logger.average()\\n>\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 미완성 (오류 x)\n",
    "# 필요한 라이브러리를 가져옵니다.\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# AverageMeter 클래스를 정의합니다.\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# 1단계: test_loop_fn를 정의합니다.\n",
    "def test_loop_fn(loader, model, device):\n",
    "    model.eval()\n",
    "    outputs, targets = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, total=len(loader))\n",
    "        for i, (image, target) in enumerate(pbar):\n",
    "            image = image.float().to(device)\n",
    "            target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            outputs.append(output.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "    print(f\"Test Metrics: {metrics}\")\n",
    "\n",
    "    # 시간을 측정하고 출력합니다.\n",
    "    end_time = time.time()\n",
    "    print(f\"Total test time: {end_time - start_time} seconds\")\n",
    "\n",
    "# 2단계: TEST_LOOP_FN를 실행합니다.\n",
    "test_loop_fn(test_loader, model, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성\n",
    "\n",
    "# 필요한 라이브러리를 설치합니다.\n",
    "!pip install pytorch-gradcam\n",
    "\n",
    "# 필요한 라이브러리를 가져옵니다.\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAMpp, GradCAM\n",
    "\n",
    "# test_loop_fn를 수정하고 Grad-CAM 시각화를 추가합니다.\n",
    "def test_loop_fn(loader, model, device):\n",
    "    model.eval()\n",
    "    outputs, targets = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 마지막 컨볼루션 레이어의 Grad-CAM을 설정합니다.\n",
    "    grad_cam = GradCAM(model, model.model.layer4)\n",
    "\n",
    "    pbar = tqdm(loader, total=len(loader))\n",
    "    for i, (image, target) in enumerate(pbar):\n",
    "        image = image.float().to(device)\n",
    "        target = target.float().unsqueeze(1).to(device)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        # Grad-CAM 마스크를 생성합니다.\n",
    "        mask, _ = grad_cam(image)\n",
    "        heatmap, result = visualize_cam(mask, image)\n",
    "\n",
    "        outputs.append(output.detach().cpu())\n",
    "        targets.append(target.detach().cpu())\n",
    "\n",
    "        # 원본 이미지와 Grad-CAM 결과를 함께 출력합니다.\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image.cpu().squeeze().numpy())\n",
    "        plt.title(f\"Label: {target.item()}\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(result.cpu().squeeze().numpy().transpose(1, 2, 0))\n",
    "        plt.title(f\"Model Result: {output.sigmoid().item()}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    outputs = torch.stack(outputs).squeeze().sigmoid()\n",
    "    targets = torch.stack(targets).squeeze().numpy()\n",
    "\n",
    "    accuracy, precision, recall, f1, auc_roc = calculate_metrics(target=targets, prediction=outputs.round().numpy(), prob=outputs.numpy())\n",
    "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_roc\": auc_roc}\n",
    "\n",
    "    print(f\"Test Metrics: {metrics}\")\n",
    "\n",
    "    # 시간을 측정하고 출력합니다.\n",
    "    end_time = time.time()\n",
    "    print(f\"Total test time: {end_time - start_time} seconds\")\n",
    "\n",
    "# test_loop_fn를 실행합니다.\n",
    "test_loop_fn(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test_auc': 0.6432500743383883, \n",
    "'test_accuracy': 0.5862068965517241, \n",
    "'test_f1': 0.6000000000000001, \n",
    "'test_sensitivity': 0.6101694915254238, \n",
    "'test_specificity': 0.5614035087719298\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
